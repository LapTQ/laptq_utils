{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import cv2\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "import PIL.Image\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from laptq_pyutils.ops import box__miniou\n",
    "from laptq_pyutils.objects import ListAligner\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from laptq_pyutils.draw import cv2_putText, cv2_rectangle\n",
    "from IPython.display import clear_output, Image, display\n",
    "\n",
    "\n",
    "HERE = Path('/mnt/hdd10tb/Users/laptq/laptq-prj-46/notebooks')\n",
    "ROOT_DIR = HERE.parent\n",
    "sys.path.append(str(ROOT_DIR))\n",
    "\n",
    "\n",
    "def imshow(a, fmt='jpeg'):\n",
    "    a = a[:,:,::-1]\n",
    "    a = np.uint8(np.clip(a, 0, 255))\n",
    "    f = io.BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    display(Image(data=f.getvalue()))\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH__DIR__DATASETS__SOURCE__IMG=\"/mnt/hdd10tb/Users/laptq/laptq-prj-46/data/road-issues-detection\"\n",
    "POSTFIX__DIR__IMG=\"--20241128--phase-2--annotated-ver2--pot-man-drain--checked--crop-top50-side20-botom0\"\n",
    "\n",
    "PATH__DIR__DATASETS__SOURCE__LBL_GT=\"/mnt/hdd10tb/Users/laptq/laptq-prj-46/outputs/20241208--true-labels--json\"\n",
    "POSTFIX__DIR__LBL_GT=\"--20241128--phase-2--annotated-ver2--pot-man-drain--checked--crop-top50-side20-botom0\"\n",
    "\n",
    "NAME__MODEL = 'yolo11m--960--crop-20'\n",
    "VER__TRAIN = 'train3'\n",
    "\n",
    "PATH__DIR__DATASETS__SOURCE__LBL_PRED=\"/mnt/hdd10tb/Users/laptq/laptq-prj-46/outputs/20241208--model-prediction--json--filterby-conf-miniou/{}/{}\".format(NAME__MODEL, VER__TRAIN)\n",
    "# PATH__DIR__DATASETS__SOURCE__LBL_PRED=\"/mnt/hdd10tb/Users/laptq/laptq-prj-46/outputs/20241208--model-prediction--json--filterby-conf/{}/{}\".format(NAME__MODEL, VER__TRAIN)\n",
    "POSTFIX__DIR__LBL_PRED=\"--20241128--phase-2--annotated-ver2--pot-man-drain--checked--crop-top50-side20-botom0\"\n",
    "\n",
    "MAP__SUBPATH_DIR__TO__={\n",
    "    \"Pothole_235/train\": \"\",\n",
    "    \"Pothole_Maeda/first_shot_eval\": \"\",\n",
    "}\n",
    "PATH__DIR__OUTPUT=\"/mnt/hdd10tb/Users/laptq/laptq-prj-46/outputs/20241208--error--analysis/{}/{}\".format(NAME__MODEL, VER__TRAIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH__DIR__OUTPUT__CROPS__GT = os.path.join(PATH__DIR__OUTPUT, 'crops--gt')\n",
    "PATH__DIR__OUTPUT__CROPS__PRED = os.path.join(PATH__DIR__OUTPUT, 'crops--pred')\n",
    "PATH__FILE__INFO_CROPS__PRED = os.path.join(PATH__DIR__OUTPUT, 'info_crops__pred.pkl')\n",
    "PATH__DIR__OUTPUT__SRC_IMG__VIS = os.path.join(PATH__DIR__OUTPUT, 'src-img--visualize')\n",
    "PATH__FILE__DF_PREPROCESSED = os.path.join(PATH__DIR__OUTPUT, 'df_preprocessed.pkl')\n",
    "# DIR_OUTPUT_BINS = '/mnt/hdd10tb/Users/laptq/laptq-prj-46/outputs/20241031-cropped-object-{}/bins'.format(DATA_SUBSET)\n",
    "PATH__DIR__WORKSHEET = os.path.join(PATH__DIR__OUTPUT, 'worksheets')\n",
    "# DIR_FP_FN_ROOT_CAUSE_WORKSHEETS = '/mnt/hdd10tb/Users/laptq/laptq-prj-46/outputs/20241105--FP-FN-worksheets/{}'.format(\n",
    "#     {\n",
    "#         'train': 'train',\n",
    "#         'Pothole_235': 'validation',\n",
    "#         'Pothole_Maeda_firstshot_eval': 'test',\n",
    "#     }[DATA_SUBSET]\n",
    "# )\n",
    "# DIR_CROP_BY_ROOT_CAUSE = '/mnt/hdd10tb/Users/laptq/laptq-prj-46/outputs/20241105--FP-FN-by-root-cause/{}'.format({\n",
    "#         'train': 'train',\n",
    "#         'Pothole_235': 'validation',\n",
    "#         'Pothole_Maeda_firstshot_eval': 'test',\n",
    "#     }[DATA_SUBSET]\n",
    "# )\n",
    "IMGSZ = 960\n",
    "MODE__IOU_EVAL = 'MINIOU' # 'NORMAL' 'MINIOU'\n",
    "THRESH__IOU = 0.5\n",
    "THRESH__MINIOU = 0.5\n",
    "MODE__EVAL__MATCHING = 'many-many' # 'one-one' 'many-many'\n",
    "BINS = [0, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "BINS_LABEL = ['({}, {}]'.format(BINS[_], BINS[_ + 1]) for _ in range(len(BINS) - 1)]\n",
    "PAD__CROP = 80\n",
    "FONTSCALE = 0.7\n",
    "THICKNESS = 1\n",
    "\n",
    "MAP__ID_CLASS__TO__NAME = {\n",
    "    0: 'pot',\n",
    "    1: 'man',\n",
    "    2: 'drain'\n",
    "}\n",
    "\n",
    "NUM__CROP__VERIFY = 500\n",
    "\n",
    "# get image paths and label paths\n",
    "list__path__file__img = []\n",
    "list__name__file__img = []\n",
    "list__subpath__dir = []\n",
    "list__name__file__lbl = []\n",
    "list__path__file__lbl_gt = []\n",
    "list__path__file__lbl_pred = []\n",
    "for subpath__dir in sorted(list(MAP__SUBPATH_DIR__TO__.keys())):\n",
    "    path__dir__img = os.path.join(PATH__DIR__DATASETS__SOURCE__IMG, subpath__dir, \"images{}\".format(POSTFIX__DIR__IMG))\n",
    "    path__dir__lbl_gt = os.path.join(PATH__DIR__DATASETS__SOURCE__LBL_GT, subpath__dir, \"labels{}\".format(POSTFIX__DIR__LBL_GT))\n",
    "    path__dir__lbl_pred = os.path.join(PATH__DIR__DATASETS__SOURCE__LBL_PRED, subpath__dir, \"labels{}\".format(POSTFIX__DIR__LBL_PRED))\n",
    "\n",
    "    for name__file__img in sorted(os.listdir(path__dir__img)):\n",
    "        path__file__img = os.path.join(path__dir__img, name__file__img)\n",
    "        name__file__lbl = os.path.splitext(name__file__img)[0] + '.json'\n",
    "        path__file__lbl_gt = os.path.join(path__dir__lbl_gt, name__file__lbl)\n",
    "        path__file__lbl_pred = os.path.join(path__dir__lbl_pred, name__file__lbl)\n",
    "\n",
    "\n",
    "        if not os.path.isfile(path__file__lbl_gt):\n",
    "            raise Exception(\"File not found: {}\".format(path__file__lbl_gt))\n",
    "        if not os.path.isfile(path__file__lbl_pred):\n",
    "            raise Exception(\"File not found: {}\".format(path__file__lbl_pred))\n",
    "        \n",
    "        list__path__file__img.append(path__file__img)\n",
    "        list__name__file__img.append(name__file__img)\n",
    "        list__subpath__dir.append(subpath__dir)\n",
    "        list__name__file__lbl.append(name__file__lbl)\n",
    "        list__path__file__lbl_gt.append(path__file__lbl_gt)\n",
    "        list__path__file__lbl_pred.append(path__file__lbl_pred)\n",
    "\n",
    "print(len(list__path__file__img), len(list__path__file__lbl_gt), len(list__path__file__lbl_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# = Extract GT crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANGER ZONE!!!\n",
    "os.system('rm -r {}'.format(PATH__DIR__OUTPUT__CROPS__GT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labels\n",
    "list__label_gt = []\n",
    "for path__lbl_gt in tqdm(list__path__file__lbl_gt):\n",
    "    with open(path__lbl_gt, 'r') as f:\n",
    "        dict_result__gt = json.load(f)\n",
    "    list__label_gt.append(dict_result__gt)\n",
    "\n",
    "list_aliger__info__gt = ListAligner(\n",
    "    list__key=[\n",
    "        'list__box__cls__gt',\n",
    "        'list__box__xcycwh__gt',\n",
    "        'list__box__path_src_img__gt',  # store source image\n",
    "        'list__box__index_lbl__gt',     # store index in the label file\n",
    "        'list__box__path_crop__gt',     # store path of the crop image\n",
    "        'list__box__subpath_dir__gt',   # store subpath of the crop image\n",
    "        'list__box__src_img_W__gt',\n",
    "        'list__box__src_img_H__gt',\n",
    "    ]\n",
    ")\n",
    "\n",
    "# load boxes\n",
    "for (\n",
    "    name__file__img,\n",
    "    path__file__img,\n",
    "    subpath__dir,\n",
    "    lbl_gt,\n",
    ") in tqdm(zip(\n",
    "    list__name__file__img,\n",
    "    list__path__file__img,\n",
    "    list__subpath__dir,\n",
    "    list__label_gt,\n",
    ")):\n",
    "    img__org = cv2.imread(path__file__img)\n",
    "    H, W = img__org.shape[:2]\n",
    "\n",
    "    for i_b, (id_class, box) in enumerate(\n",
    "        zip(lbl_gt['list__obj__id_class'], lbl_gt['list__obj__box_xcycwhn'])\n",
    "    ):\n",
    "        xcn, ycn, wn, hn = box\n",
    "        xc = int(xcn * W)\n",
    "        yc = int(ycn * H)\n",
    "        w = int(wn * W)\n",
    "        h = int(hn * H)\n",
    "        x1 = int(xc - w / 2)\n",
    "        y1 = int(yc - h / 2)\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        img = img__org.copy()\n",
    "        cv2_rectangle(img, (x1, y1), (x2, y2), color=(0, 255, 0), thickness=THICKNESS)\n",
    "        cv2_putText(img, MAP__ID_CLASS__TO__NAME[id_class], (x1, y1 - THICKNESS - 5), color=(0, 255, 0), fontScale=FONTSCALE, thickness=THICKNESS)\n",
    "        img__crop = img[y1:y2, x1:x2]\n",
    "        img__crop__padded = img[max(0, y1 - PAD__CROP):y2 + PAD__CROP, max(0, x1 - PAD__CROP):x2 + PAD__CROP]\n",
    "        name__file__crop = \"{}--crop-{}.jpg\".format(os.path.splitext(name__file__img)[0], i_b)\n",
    "        path__dir__parent = os.path.join(PATH__DIR__OUTPUT__CROPS__GT, subpath__dir)\n",
    "        os.makedirs(path__dir__parent, exist_ok=True)\n",
    "        path_crop = os.path.join(path__dir__parent, name__file__crop)\n",
    "        try:\n",
    "            cv2.imwrite(path_crop, img__crop__padded)\n",
    "        except:\n",
    "            print(img__crop__padded)\n",
    "            continue\n",
    "\n",
    "        list_aliger__info__gt.append(\n",
    "            {\n",
    "                'list__box__cls__gt': id_class,\n",
    "                'list__box__xcycwh__gt': [xc, yc, w, h],\n",
    "                'list__box__path_src_img__gt': path__file__img,\n",
    "                'list__box__index_lbl__gt': i_b,\n",
    "                'list__box__path_crop__gt': path_crop,\n",
    "                'list__box__subpath_dir__gt': subpath__dir,\n",
    "                'list__box__src_img_W__gt': W,\n",
    "                'list__box__src_img_H__gt': H,\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view some crops\n",
    "list_indexes_sampled = np.random.choice(range(len(list_aliger__info__gt.get__key('list__box__path_crop__gt'))), size=3, replace=False)\n",
    "for i_sampled in list_indexes_sampled:\n",
    "    xcycwh = list_aliger__info__gt.get__key('list__box__xcycwh__gt')[i_sampled]\n",
    "    path_crop = list_aliger__info__gt.get__key('list__box__path_crop__gt')[i_sampled]\n",
    "    crop_img = cv2.imread(path_crop)\n",
    "    print('\\n=== path_crop = {} ==='.format(path_crop))\n",
    "    imshow(crop_img)\n",
    "    print('xcycwh = ', xcycwh)\n",
    "    print('crop_img.shape = ', crop_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# = Extract Pred crops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANGER ZONE!!!\n",
    "os.system('rm -r {}'.format(PATH__DIR__OUTPUT__CROPS__PRED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load labels\n",
    "list__label_pred = []\n",
    "for path__lbl_pred in tqdm(list__path__file__lbl_pred):\n",
    "    with open(path__lbl_pred, 'r') as f:\n",
    "        dict_result__pred = json.load(f)\n",
    "    list__label_pred.append(dict_result__pred)\n",
    "\n",
    "list_aliger__info__pred = ListAligner(\n",
    "    list__key=[\n",
    "        'list__box__cls__pred',\n",
    "        'list__box__xcycwh__pred',\n",
    "        'list__box__path_src_img__pred',\n",
    "        'list__box__index_lbl__pred',\n",
    "        'list__box__path_crop__pred',\n",
    "        'list__box__conf__pred',\n",
    "        'list__box__subpath_dir__pred',\n",
    "        'list__box__src_img_W__pred',\n",
    "        'list__box__src_img_H__pred',\n",
    "    ]\n",
    ")\n",
    "\n",
    "# load boxes\n",
    "for (\n",
    "    name__file__img,\n",
    "    path__file__img,\n",
    "    subpath__dir,\n",
    "    lbl_pred,\n",
    ") in tqdm(zip(\n",
    "    list__name__file__img,\n",
    "    list__path__file__img,\n",
    "    list__subpath__dir,\n",
    "    list__label_pred,\n",
    ")):\n",
    "    img__org = cv2.imread(path__file__img)\n",
    "    H, W = img__org.shape[:2]\n",
    "\n",
    "    for i_b, (id_class, box, conf) in enumerate(\n",
    "        zip(lbl_pred['list__obj__id_class'], lbl_pred['list__obj__box_xcycwhn'], lbl_pred['list__obj__box_conf'])\n",
    "    ):\n",
    "        xcn, ycn, wn, hn = box\n",
    "        xc = int(xcn * W)\n",
    "        yc = int(ycn * H)\n",
    "        w = int(wn * W)\n",
    "        h = int(hn * H)\n",
    "        x1 = int(xc - w / 2)\n",
    "        y1 = int(yc - h / 2)\n",
    "        x2 = x1 + w\n",
    "        y2 = y1 + h\n",
    "        img = img__org.copy()\n",
    "        cv2_rectangle(img, (x1, y1), (x2, y2), color=(255, 50, 255), thickness=THICKNESS)\n",
    "        cv2_putText(img, \"{} {:.2f}\".format(MAP__ID_CLASS__TO__NAME[id_class], conf) , (x1, y1 - THICKNESS - 5), color=(255, 50, 255), fontScale=FONTSCALE, thickness=THICKNESS)\n",
    "        img__crop = img[y1:y2, x1:x2]\n",
    "        img__crop__padded = img[max(0, y1 - PAD__CROP):y2 + PAD__CROP, max(0, x1 - PAD__CROP):x2 + PAD__CROP]\n",
    "        name__file__crop = \"{}--crop-{}.jpg\".format(os.path.splitext(name__file__img)[0], i_b)\n",
    "        path__dir__parent = os.path.join(PATH__DIR__OUTPUT__CROPS__PRED, subpath__dir)\n",
    "        os.makedirs(path__dir__parent, exist_ok=True)\n",
    "        path_crop = os.path.join(path__dir__parent, name__file__crop)\n",
    "        try:\n",
    "            cv2.imwrite(path_crop, img__crop__padded)\n",
    "        except:\n",
    "            print(img__crop__padded)\n",
    "            continue\n",
    "\n",
    "        list_aliger__info__pred.append(\n",
    "            {\n",
    "                'list__box__cls__pred': id_class,\n",
    "                'list__box__xcycwh__pred': [xc, yc, w, h],\n",
    "                'list__box__path_src_img__pred': path__file__img,\n",
    "                'list__box__index_lbl__pred': i_b,\n",
    "                'list__box__path_crop__pred': path_crop,\n",
    "                'list__box__conf__pred': conf,\n",
    "                'list__box__subpath_dir__pred': subpath__dir,\n",
    "                'list__box__src_img_W__pred': W,\n",
    "                'list__box__src_img_H__pred': H,\n",
    "            }\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_indexes_sampled = np.random.choice(range(len(list_aliger__info__pred.get__key('list__box__path_crop__pred'))), size=3, replace=False)\n",
    "for i_sampled in list_indexes_sampled:\n",
    "    xcycwh = list_aliger__info__pred.get__key('list__box__xcycwh__pred')[i_sampled]\n",
    "    path_crop = list_aliger__info__pred.get__key('list__box__path_crop__pred')[i_sampled]\n",
    "    crop_img = cv2.imread(path_crop)\n",
    "    print('\\n=== path_crop = {} ==='.format(path_crop))\n",
    "    imshow(crop_img)\n",
    "    print('xcycwh = ', xcycwh)\n",
    "    print('crop_img.shape = ', crop_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# = Preprocess and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine GT and Pred into a table\n",
    "info_crops_all = {\n",
    "    'list__box__cls': list_aliger__info__gt.get__key('list__box__cls__gt') + list_aliger__info__pred.get__key('list__box__cls__pred'),\n",
    "    'list__box__xcycwh': list_aliger__info__gt.get__key('list__box__xcycwh__gt') + list_aliger__info__pred.get__key('list__box__xcycwh__pred'),\n",
    "    'list__box__path_src_img': list_aliger__info__gt.get__key('list__box__path_src_img__gt') + list_aliger__info__pred.get__key('list__box__path_src_img__pred'),\n",
    "    'list__box__index_lbl': list_aliger__info__gt.get__key('list__box__index_lbl__gt') + list_aliger__info__pred.get__key('list__box__index_lbl__pred'),\n",
    "    'list__box__path_crop': list_aliger__info__gt.get__key('list__box__path_crop__gt') + list_aliger__info__pred.get__key('list__box__path_crop__pred'),\n",
    "    'list__box__conf': [1] * len(list_aliger__info__gt) + list_aliger__info__pred.get__key('list__box__conf__pred'),\n",
    "    'list__box__type': ['gt'] * len(list_aliger__info__gt) + ['pred'] * len(list_aliger__info__pred),\n",
    "    'list__box__subpath_dir': list_aliger__info__gt.get__key('list__box__subpath_dir__gt') + list_aliger__info__pred.get__key('list__box__subpath_dir__pred'),\n",
    "    'list__box__src_img_W': list_aliger__info__gt.get__key('list__box__src_img_W__gt') + list_aliger__info__pred.get__key('list__box__src_img_W__pred'),\n",
    "    'list__box__src_img_H': list_aliger__info__gt.get__key('list__box__src_img_H__gt') + list_aliger__info__pred.get__key('list__box__src_img_H__pred')\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(info_crops_all)\n",
    "df['w'] = df['list__box__xcycwh'].apply(lambda x: x[2])\n",
    "df['h'] = df['list__box__xcycwh'].apply(lambda x: x[3])\n",
    "df['list__box__x1y1x2y2'] = df['list__box__xcycwh'].apply(lambda x: [x[0] - x[2] // 2, x[1] - x[3] // 2, x[0] + x[2] // 2, x[1] + x[3] // 2])\n",
    "df['area'] = df['w'] * df['h']\n",
    "df['area_log'] = np.log(df['area'])\n",
    "df['area_sqrt'] = np.sqrt(df['area'])\n",
    "\n",
    "# calculate boxes size given IMGSZ\n",
    "df['w_IMGSZ'] = df.apply(lambda x: int(x['w'] * IMGSZ / max(x['list__box__src_img_W'], x['list__box__src_img_H'])), axis=1)\n",
    "df['h_IMGSZ'] = df.apply(lambda x: int(x['h'] * IMGSZ / max(x['list__box__src_img_W'], x['list__box__src_img_H'])), axis=1)\n",
    "\n",
    "df['area_IMGSZ'] = df['w_IMGSZ'] * df['h_IMGSZ']\n",
    "df['area_IMGSZ_log'] = np.log(df['area_IMGSZ'])\n",
    "df['area_IMGSZ_sqrt'] = np.sqrt(df['area_IMGSZ'])\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate boxes\n",
    "df['list__box__eval'] = None\n",
    "df['list__box__matched_to_pred__dfloc'] = None\n",
    "df['list__box__iou_to_matched_pred'] = None\n",
    "unique_paths_src_img = df['list__box__path_src_img'].unique()\n",
    "for path_src_img in tqdm(unique_paths_src_img):\n",
    "    df__of_img = df[df['list__box__path_src_img'] == path_src_img]\n",
    "    df__of_img__gt = df__of_img[df__of_img['list__box__type'] == 'gt']\n",
    "    df__of_img__pred = df__of_img[df__of_img['list__box__type'] == 'pred']\n",
    "    indices__of_img__gt = df__of_img__gt.index.to_numpy()\n",
    "    indices__of_img__pred = df__of_img__pred.index.to_numpy()\n",
    "\n",
    "    # cost by iou\n",
    "    if MODE__IOU_EVAL == 'NORMAL':\n",
    "        cost_iou = (1 - torchvision.ops.box_iou(\n",
    "            torch.tensor(df__of_img__gt['list__box__x1y1x2y2'].tolist()).reshape(-1, 4), \n",
    "            torch.tensor(df__of_img__pred['list__box__x1y1x2y2'].tolist()).reshape(-1, 4)\n",
    "        )).numpy()\n",
    "        cost_iou = np.where(cost_iou < 1 - THRESH__IOU, cost_iou, 1)\n",
    "    elif MODE__IOU_EVAL == 'MINIOU':\n",
    "        cost_iou = 1 - box__miniou(\n",
    "            np.array(df__of_img__gt['list__box__x1y1x2y2'].tolist()).reshape(-1, 4), \n",
    "            np.array(df__of_img__pred['list__box__x1y1x2y2'].tolist()).reshape(-1, 4)\n",
    "        )\n",
    "        cost_iou = np.where(cost_iou < 1 - THRESH__MINIOU, cost_iou, 1)\n",
    "    else:\n",
    "        raise ValueError('Invalid MODE__IOU_EVAL: {}'.format(MODE__IOU_EVAL))\n",
    "    # mask by class id\n",
    "    mask_cls = np.equal(\n",
    "        np.expand_dims(df__of_img__gt['list__box__cls'].tolist(), axis=1),\n",
    "        np.expand_dims(df__of_img__pred['list__box__cls'].tolist(), axis=0)\n",
    "    )\n",
    "    cost_iou = np.where(mask_cls, cost_iou, 1)\n",
    "\n",
    "    # matching\n",
    "    if MODE__EVAL__MATCHING == 'one-one':\n",
    "        matched_gt, matched_pred = linear_sum_assignment(cost_iou)\n",
    "    elif MODE__EVAL__MATCHING == 'many-many':\n",
    "        matched_gt, matched_pred = np.where(cost_iou < 1 - (THRESH__IOU if MODE__IOU_EVAL == 'NORMAL' else THRESH__MINIOU))\n",
    "    else:\n",
    "        raise ValueError('Invalid MODE__EVAL__MATCHING: {}'.format(MODE__EVAL__MATCHING))\n",
    "    unmatched_gt = [_ for _ in range(len(indices__of_img__gt)) if _ not in matched_gt]\n",
    "    unmatched_pred = [_ for _ in range(len(indices__of_img__pred)) if _ not in matched_pred]\n",
    "    matched_pred_loc_set = {}\n",
    "    matched_iou_set = {}\n",
    "    for i_gt, i_pred in zip(matched_gt, matched_pred):\n",
    "        loc_gt = indices__of_img__gt[i_gt]\n",
    "        if loc_gt not in matched_pred_loc_set:\n",
    "            matched_pred_loc_set[loc_gt] = []\n",
    "            matched_iou_set[loc_gt] = []\n",
    "        log_pred = indices__of_img__pred[i_pred]\n",
    "        matched_pred_loc_set[loc_gt].append(log_pred)\n",
    "        matched_iou_set[loc_gt].append(1 - cost_iou[i_gt, i_pred])\n",
    "    matched_gt_loc_set, matched_pred_loc_set, matched_iou_set = list(matched_pred_loc_set.keys()), list(matched_pred_loc_set.values()), list(matched_iou_set.values())\n",
    "\n",
    "    df['list__box__eval'].loc[indices__of_img__gt[matched_gt]] = 'TP'\n",
    "    df['list__box__matched_to_pred__dfloc'].loc[matched_gt_loc_set] = matched_pred_loc_set\n",
    "    df['list__box__iou_to_matched_pred'].loc[matched_gt_loc_set] = matched_iou_set\n",
    "    df['list__box__eval'].loc[indices__of_img__pred[matched_pred]] = 'TP'\n",
    "    df['list__box__eval'].loc[indices__of_img__gt[unmatched_gt]] = 'FN'\n",
    "    df['list__box__eval'].loc[indices__of_img__pred[unmatched_pred]] = 'FP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvtab_eval = df[\n",
    "    (\n",
    "        (df['list__box__eval'] == 'TP') & (df['list__box__type'] == 'gt')\n",
    "    ) \\\n",
    "        | (df['list__box__eval'] != 'TP')\n",
    "] \\\n",
    "    .groupby(['list__box__cls', 'list__box__eval']).size().reset_index(name='count') \\\n",
    "        .pivot_table(index='list__box__cls', columns='list__box__eval', values='count', fill_value=0)\n",
    "\n",
    "pvtab_eval['precision'] = pvtab_eval['TP'] / (pvtab_eval['TP'] + pvtab_eval['FP'])\n",
    "pvtab_eval['recall'] = pvtab_eval['TP'] / (pvtab_eval['TP'] + pvtab_eval['FN'])\n",
    "pvtab_eval['f1'] = 2 * pvtab_eval['precision'] * pvtab_eval['recall'] / (pvtab_eval['precision'] + pvtab_eval['recall'])\n",
    "pvtab_eval['Number-of-GT-boxes'] = pvtab_eval['TP'] + pvtab_eval['FN']\n",
    "pvtab_eval['Percentage-of-GT-boxes'] = pvtab_eval['Number-of-GT-boxes'] / pvtab_eval['Number-of-GT-boxes'].sum()\n",
    "\n",
    "pvtab_eval[\n",
    "    [\n",
    "        'precision', \n",
    "        'recall', \n",
    "        'f1', \n",
    "        'Percentage-of-GT-boxes'\n",
    "    ]\n",
    "].plot.bar()\n",
    "plt.grid(axis='y')\n",
    "plt.legend(loc='lower right', bbox_to_anchor=(1.5, 0))\n",
    "plt.show()\n",
    "\n",
    "pvtab_eval\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# = Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize GT and Pred boxes on the src_img\n",
    "os.system('rm -rf {}'.format(PATH__DIR__OUTPUT__SRC_IMG__VIS))\n",
    "os.makedirs(PATH__DIR__OUTPUT__SRC_IMG__VIS, exist_ok=True)\n",
    "locs = []\n",
    "paths_vis = []\n",
    "for path_src_img, group in tqdm(df.groupby('list__box__path_src_img')):\n",
    "    img = cv2.imread(path_src_img)\n",
    "    img_vis = img.copy()\n",
    "    for loc, row in group.iterrows():\n",
    "        box_cls = row['list__box__cls']\n",
    "        subpath__dir = row['list__box__subpath_dir']\n",
    "        path__dir__parent = os.path.join(PATH__DIR__OUTPUT__SRC_IMG__VIS, subpath__dir)\n",
    "        os.makedirs(path__dir__parent, exist_ok=True)\n",
    "        path_vis = os.path.join(path__dir__parent, os.path.basename(path_src_img))\n",
    "        x1, y1, x2, y2 = row['list__box__x1y1x2y2']\n",
    "        type_ = row['list__box__type']\n",
    "        conf = row['list__box__conf']\n",
    "        \n",
    "        if type_ == 'gt':\n",
    "            color = (50, 255, 0)\n",
    "        else:\n",
    "            color = (255, 50, 255)\n",
    "        \n",
    "        cv2_rectangle(\n",
    "            img_vis, (x1, y1), (x2, y2), \n",
    "            color=color, \n",
    "            thickness=THICKNESS,\n",
    "        )\n",
    "        cv2_putText(\n",
    "            img_vis, \n",
    "            '{} {}'.format(MAP__ID_CLASS__TO__NAME[box_cls], '{:.2f}'.format(conf) if type_ == 'pred' else ''), \n",
    "            (x1, y1 - THICKNESS - 5) if type_ == 'gt' else (x1 + 4, y2 - THICKNESS - 5), \n",
    "            fontScale=FONTSCALE, color=color, thickness=THICKNESS\n",
    "        )\n",
    "        locs.append(loc)\n",
    "        paths_vis.append(path_vis)\n",
    "    cv2.imwrite(path_vis, np.concatenate([img, img_vis], axis=0))\n",
    "\n",
    "df['list__boxes__path_src_img__vis'] = None\n",
    "df['list__boxes__path_src_img__vis'].loc[locs] = paths_vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# = Create bins and pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into bins\n",
    "df['list_boxes_bin__area_IMGSZ_sqrt'] = pd.cut(\n",
    "    df['area_IMGSZ_sqrt'], \n",
    "    bins=BINS,\n",
    "    labels=BINS_LABEL,\n",
    "    right=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count TP, FP, FN\n",
    "def get_pvtab_eval(box_cls):\n",
    "    pvtab_eval = df[\n",
    "        (df['list__box__cls'] == box_cls) \\\n",
    "            & (\n",
    "                (\n",
    "                    (df['list__box__eval'] == 'TP') & (df['list__box__type'] == 'gt')\n",
    "                ) \\\n",
    "                    | (df['list__box__eval'] != 'TP')\n",
    "            )\n",
    "    ] \\\n",
    "        .groupby(['list_boxes_bin__area_IMGSZ_sqrt', 'list__box__eval']).size().reset_index(name='count') \\\n",
    "        .pivot_table(index='list_boxes_bin__area_IMGSZ_sqrt', columns='list__box__eval', values='count', fill_value=0)\n",
    "\n",
    "    pvtab_eval['precision'] = pvtab_eval['TP'] / (pvtab_eval['TP'] + pvtab_eval['FP'])\n",
    "    pvtab_eval['recall'] = pvtab_eval['TP'] / (pvtab_eval['TP'] + pvtab_eval['FN'])\n",
    "    pvtab_eval['f1'] = 2 * pvtab_eval['precision'] * pvtab_eval['recall'] / (pvtab_eval['precision'] + pvtab_eval['recall'])\n",
    "    pvtab_eval['Number-of-GT-boxes'] = pvtab_eval['TP'] + pvtab_eval['FN']\n",
    "    pvtab_eval['Percentage-of-GT-boxes'] = pvtab_eval['Number-of-GT-boxes'] / pvtab_eval['Number-of-GT-boxes'].sum()\n",
    "\n",
    "    return pvtab_eval\n",
    "\n",
    "dict__pvtab__eval = {id_class: get_pvtab_eval(box_cls=id_class) for id_class in MAP__ID_CLASS__TO__NAME.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pothole\n",
    "id_class = 0\n",
    "\n",
    "dict__pvtab__eval[id_class][\n",
    "    [\n",
    "        'precision', \n",
    "        'recall', \n",
    "        'f1', \n",
    "        'Percentage-of-GT-boxes'\n",
    "    ]\n",
    "].plot.bar()\n",
    "plt.grid(axis='y')\n",
    "plt.legend(loc='lower right', bbox_to_anchor=(1.5, 0))\n",
    "plt.title(MAP__ID_CLASS__TO__NAME[id_class])\n",
    "plt.show()\n",
    "\n",
    "dict__pvtab__eval[id_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manhole\n",
    "id_class = 1\n",
    "\n",
    "dict__pvtab__eval[id_class][\n",
    "    [\n",
    "        'precision', \n",
    "        'recall', \n",
    "        'f1', \n",
    "        'Percentage-of-GT-boxes'\n",
    "    ]\n",
    "].plot.bar()\n",
    "plt.grid(axis='y')\n",
    "plt.legend(loc='lower right', bbox_to_anchor=(1.5, 0))\n",
    "plt.title(MAP__ID_CLASS__TO__NAME[id_class])\n",
    "plt.show()\n",
    "\n",
    "dict__pvtab__eval[id_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drainage\n",
    "id_class = 2\n",
    "\n",
    "dict__pvtab__eval[id_class][\n",
    "    [\n",
    "        'precision', \n",
    "        'recall', \n",
    "        'f1', \n",
    "        'Percentage-of-GT-boxes'\n",
    "    ]\n",
    "].plot.bar()\n",
    "plt.grid(axis='y')\n",
    "plt.legend(loc='lower right', bbox_to_anchor=(1.5, 0))\n",
    "plt.title(MAP__ID_CLASS__TO__NAME[id_class])\n",
    "plt.show()\n",
    "\n",
    "dict__pvtab__eval[id_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean conf of TP, FP, FN\n",
    "def get_pvtab_conf(box_cls):\n",
    "    pvtab_conf = df[(df['list__box__cls'] == box_cls) & (((df['list__box__eval'] == 'TP') & (df['list__box__type'] == 'pred')) | (df['list__box__eval'] != 'FN'))] \\\n",
    "        .groupby(['list_boxes_bin__area_IMGSZ_sqrt', 'list__box__eval'])['list__box__conf'].mean().reset_index(name='conf') \\\n",
    "            .pivot_table(index='list_boxes_bin__area_IMGSZ_sqrt', columns='list__box__eval', values='conf', fill_value=0)\n",
    "\n",
    "    return pvtab_conf\n",
    "\n",
    "dict__pvtab__conf = {id_class: get_pvtab_conf(box_cls=id_class) for id_class in MAP__ID_CLASS__TO__NAME.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pothole\n",
    "id_class = 0\n",
    "\n",
    "dict__pvtab__conf[id_class].plot.bar()\n",
    "plt.grid(axis='y')\n",
    "plt.legend(loc='lower right', bbox_to_anchor=(1.2, 0))\n",
    "plt.ylabel('Mean confidence score')\n",
    "plt.title(MAP__ID_CLASS__TO__NAME[id_class])\n",
    "plt.show()\n",
    "\n",
    "dict__pvtab__conf[id_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manhole\n",
    "id_class = 1\n",
    "\n",
    "dict__pvtab__conf[id_class].plot.bar()\n",
    "plt.grid(axis='y')\n",
    "plt.legend(loc='lower right', bbox_to_anchor=(1.2, 0))\n",
    "plt.ylabel('Mean confidence score')\n",
    "plt.title(MAP__ID_CLASS__TO__NAME[id_class])\n",
    "plt.show()\n",
    "\n",
    "dict__pvtab__conf[id_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drainage\n",
    "id_class = 2\n",
    "\n",
    "dict__pvtab__conf[id_class].plot.bar()\n",
    "plt.grid(axis='y')\n",
    "plt.legend(loc='lower right', bbox_to_anchor=(1.2, 0))\n",
    "plt.ylabel('Mean confidence score')\n",
    "plt.title(MAP__ID_CLASS__TO__NAME[id_class])\n",
    "plt.show()\n",
    "\n",
    "dict__pvtab__conf[id_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## == Determine root causes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === Select NUM__CROP__VERIFY failed cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(PATH__DIR__WORKSHEET, exist_ok=True)\n",
    "\n",
    "for box_cls in MAP__ID_CLASS__TO__NAME:\n",
    "    workbook = xlsxwriter.Workbook(os.path.join(PATH__DIR__WORKSHEET, \"{}.xlsx\".format(MAP__ID_CLASS__TO__NAME[box_cls])))\n",
    "    cols_select = ['list__box__conf', 'list__box__type', 'w', 'h', 'w_IMGSZ', 'h_IMGSZ', 'list__box__eval']\n",
    "    for bin_, group in df[(df['list__box__eval'] != 'TP') & (df['list__box__cls'] == box_cls)].groupby('list_boxes_bin__area_IMGSZ_sqrt'):\n",
    "        worksheet = workbook.add_worksheet(bin_.strip('(').strip(']').replace(', ', '-'))\n",
    "        size = min(len(group), NUM__CROP__VERIFY)\n",
    "        worksheet.write_row(0, 0, ['loc'] + cols_select + ['crop_img', 'root-cause', 'source-image'])\n",
    "        subset = group.sample(size, replace=False, random_state=42)\n",
    "        row_count = 1\n",
    "        max_crop_width = 80\n",
    "        offset = 5\n",
    "        for loc, row in subset.iterrows():\n",
    "            worksheet.write_row(row_count, 0, [loc] + row[cols_select].tolist())\n",
    "            path_crop = row['list__box__path_crop']\n",
    "            crop_W, crop_H = PIL.Image.open(path_crop).size\n",
    "            max_crop_H = 180\n",
    "            crop_scale = min(1, max_crop_H / crop_H)\n",
    "            max_crop_width = max(max_crop_width, int(crop_W * crop_scale))\n",
    "            worksheet.insert_image(row_count, len(cols_select) + 1, path_crop, {'x_scale': crop_scale, 'y_scale': crop_scale})\n",
    "            worksheet.set_row_pixels(row_count, max(25, min(crop_H, max_crop_H)) + offset)\n",
    "            worksheet.write(row_count, len(cols_select) + 3, row['list__boxes__path_src_img__vis'])\n",
    "            row_count += 1\n",
    "        worksheet.autofit()\n",
    "        worksheet.set_column_pixels(len(cols_select) + 1, len(cols_select) + 1, max_crop_width + offset)\n",
    "        worksheet.set_column_pixels(len(cols_select) + 2, len(cols_select) + 2, 400)\n",
    "    workbook.close()\n",
    "    print(\"Saved: {}\".format(workbook.filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === Root causes statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pvtab_root_cause(box_cls):\n",
    "    path_excel = os.path.join(DIR_FP_FN_ROOT_CAUSE_WORKSHEETS, '{}.xlsx'.format(MAP__ID_CLASS__TO__NAME[box_cls]))\n",
    "    df_root_cause = []\n",
    "    for bin_ in df['list_boxes_bin__area_IMGSZ_sqrt'].unique().sort_values():\n",
    "        sheet = pd.read_excel(path_excel, sheet_name=bin_.strip('(').strip(']').replace(', ', '-'), index_col=0)\n",
    "        sheet['root-cause'] = sheet['root-cause'].apply(lambda x: x.strip().strip('.').strip().encode('ascii', 'ignore').decode('ascii').lower())\n",
    "        sheet_count = sheet.groupby(['root-cause', 'list__box__eval']).size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "        sheet_count['percentage'] = sheet_count['count'] / sheet_count['count'].sum() * 100\n",
    "        sheet_count['list_boxes_bin__area_IMGSZ_sqrt'] = bin_\n",
    "        df_root_cause.append(sheet_count)\n",
    "\n",
    "    df_root_cause = pd.concat(df_root_cause, axis=0)\n",
    "    df_root_cause = df_root_cause.reset_index(drop=True)\n",
    "    pvtab_root_cause = df_root_cause.groupby(['root-cause', 'list_boxes_bin__area_IMGSZ_sqrt']).sum().pivot_table(index='list_boxes_bin__area_IMGSZ_sqrt', columns='root-cause', values='percentage')\n",
    "    pvtab_root_cause = pvtab_root_cause.loc[df_root_cause['list_boxes_bin__area_IMGSZ_sqrt'].unique()]\n",
    "\n",
    "    return df_root_cause, pvtab_root_cause\n",
    "\n",
    "def helper_aggregate_root_cause(df_root_cause, eval_):\n",
    "    print('FP + FN:' if eval_ is None else eval_)\n",
    "    df_root_cause = df_root_cause[df_root_cause['list__box__eval'] == eval_] if eval_ is not None else df_root_cause\n",
    "    df_root_cause = df_root_cause[['root-cause', 'count']].groupby('root-cause').sum()\n",
    "    df_root_cause['percentage'] = df_root_cause['count'] / df_root_cause['count'].sum() * 100\n",
    "    df_root_cause = df_root_cause.reset_index().sort_values(by='percentage', ascending=False)\n",
    "    return df_root_cause\n",
    "\n",
    "df_root_cause_pothole, pvtab_root_cause_pothole = get_pvtab_root_cause(0)\n",
    "df_root_cause_manhole, pvtab_root_cause_manhole = get_pvtab_root_cause(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvtab_root_cause_pothole.plot.bar(figsize=(15, 9))\n",
    "plt.title(MAP__ID_CLASS__TO__NAME[0])\n",
    "plt.show()\n",
    "\n",
    "df_root_cause_pothole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_aggregate_root_cause(df_root_cause_pothole, eval_=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_aggregate_root_cause(df_root_cause_pothole, eval_='FP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_aggregate_root_cause(df_root_cause_pothole, eval_='FN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvtab_root_cause_manhole.plot.bar(figsize=(15, 9))\n",
    "plt.title(MAP__ID_CLASS__TO__NAME[1])\n",
    "plt.show()\n",
    "\n",
    "df_root_cause_manhole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_aggregate_root_cause(df_root_cause_manhole, eval_=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_aggregate_root_cause(df_root_cause_manhole, eval_='FP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper_aggregate_root_cause(df_root_cause_manhole, eval_='FN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### === Arrange failed crops into folders by root causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for box_cls in MAP__ID_CLASS__TO__NAME:\n",
    "    path_excel = os.path.join(DIR_FP_FN_ROOT_CAUSE_WORKSHEETS, '{}.xlsx'.format(MAP__ID_CLASS__TO__NAME[box_cls]))\n",
    "    df_root_cause = []\n",
    "    for bin_ in df['list_boxes_bin__area_IMGSZ_sqrt'].unique().sort_values():\n",
    "        sheet = pd.read_excel(path_excel, sheet_name=bin_.strip('(').strip(']').replace(', ', '-'), index_col=0)\n",
    "        sheet['root-cause'] = sheet['root-cause'].apply(lambda x: x.strip().strip('.').strip().encode('ascii', 'ignore').decode('ascii').lower())\n",
    "        df_root_cause.append(sheet)\n",
    "\n",
    "    df_root_cause = pd.concat(df_root_cause, axis=0)\n",
    "    for loc, row in tqdm(df_root_cause.iterrows()):\n",
    "        path_crop__padded = df.loc[loc]['list__box__path_crop']\n",
    "        path_src_img = df.loc[loc]['list__box__path_src_img']\n",
    "        path_src_img_vis = df.loc[loc]['list__boxes__path_src_img__vis']\n",
    "        dir_output = os.path.join(DIR_CROP_BY_ROOT_CAUSE, MAP__ID_CLASS__TO__NAME[box_cls], row['root-cause'].replace(' ', '-').replace('(', '').replace(')', '').replace('/', '-'), row['list__box__eval'])\n",
    "        dir_output_crop = os.path.join(dir_output, 'crop')\n",
    "        dir_output_src_img = os.path.join(dir_output, 'source-image')\n",
    "        dir_output_src_img_vis = os.path.join(dir_output, 'source-image-visualized')\n",
    "        os.makedirs(dir_output_crop, exist_ok=True)\n",
    "        os.makedirs(dir_output_src_img, exist_ok=True)\n",
    "        os.makedirs(dir_output_src_img_vis, exist_ok=True)\n",
    "        os.system('cp \"{}\" \"{}\"'.format(path_crop__padded, dir_output_crop))\n",
    "        os.system('cp \"{}\" \"{}\"'.format(path_src_img, dir_output_src_img))\n",
    "        os.system('cp \"{}\" \"{}\"'.format(path_src_img_vis, dir_output_src_img_vis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## == Remove objects that are too small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['list_boxes_bin__area_IMGSZ_sqrt'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_out = '/mnt/hdd10tb/Users/laptq/laptq-prj-46/outputs/20241115--small'\n",
    "os.system('rm -rf {}'.format(dir_out))\n",
    "os.makedirs(dir_out, exist_ok=True)\n",
    "\n",
    "for loc, row in tqdm(df[df['list_boxes_bin__area_IMGSZ_sqrt'] == '(16, 32]'].iterrows()):\n",
    "    path_crop__padded = row['list__box__path_crop']\n",
    "    os.system('cp \"{}\" \"{}\"'.format(path_crop__padded, dir_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## == Drawing stuffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show cases\n",
    "bin_ = '(64, 128]'\n",
    "box_cls = 0\n",
    "eval_ = 'FN'\n",
    "\n",
    "for i, (idx, row) in enumerate(\n",
    "    df[\n",
    "        (df['list_boxes_bin__area_IMGSZ_sqrt'] == bin_) \\\n",
    "            & (df['list__box__eval'] == eval_) \\\n",
    "                & (df['list__box__cls'] == box_cls)\n",
    "    ].iterrows()\n",
    "):\n",
    "    path_img = row['list__box__path_crop']\n",
    "    path_src_img = row['list__box__path_src_img']\n",
    "    path_src_img = os.path.join(PATH__DIR__OUTPUT__SRC_IMG__VIS, os.path.split(path_src_img)[1])\n",
    "    \n",
    "    if i > 10:\n",
    "        break\n",
    "    print(row[['list__box__cls', 'list__box__conf', 'list__box__eval', 'w', 'h', 'w_IMGSZ', 'h_IMGSZ', 'area_IMGSZ_sqrt']])\n",
    "    imshow(cv2.imread(path_img))\n",
    "    imshow(cv2.imread(path_src_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange crops into subfolders\n",
    "os.system(\"rm -rf {}\".format(DIR_OUTPUT_BINS))\n",
    "os.makedirs(DIR_OUTPUT_BINS, exist_ok=True)\n",
    "\n",
    "for i_loc, row in tqdm(df.iterrows()):\n",
    "    box_cls = row['list__box__cls']\n",
    "    path_crop = row['list__box__path_crop']\n",
    "    conf = row['list__box__conf']\n",
    "    type_ = row['list__box__type']\n",
    "    eval_ = row['list__box__eval']\n",
    "    bin_ = row['list_boxes_bin__area_IMGSZ_sqrt']\n",
    "    if type_ == 'pred' and eval_ == 'TP':\n",
    "        continue\n",
    "    _dir_output = os.path.join(DIR_OUTPUT_BINS, '{}'.format('pothole' if box_cls == 0 else 'manhole'), bin_.strip('(').strip(']').replace(', ','-'), eval_)\n",
    "    _path_output = os.path.join(_dir_output, '{}-{}.jpg'.format(os.path.splitext(os.path.split(path_crop)[1])[0], conf))\n",
    "    os.makedirs(_dir_output, exist_ok=True)\n",
    "    os.system('cp \"{}\" \"{}\"'.format(path_crop, _path_output))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-prj46",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
